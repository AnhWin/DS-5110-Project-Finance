{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS 5110 Project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPfwegD0JgAFReSNJxtwoEX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnhWin/DS-5110-Project-Finance/blob/main/DS_5110_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Team Number: 7 <br>\n",
        "## Team Members: Connor Killion (cmk7xr), Thomas McIntyre (gem5cm), Anh Nguyen (hzn3kf) <br>\n",
        "## Topic: Finance"
      ],
      "metadata": {
        "id": "kt9vc7Q3bnOg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Research Question:\n",
        "\n",
        "Based on financial metrics of the S&P 500 index, other industries performance, and its own performance within a past time period (quarters or others), can we predict an industry performance for the upcoming time period. And if time allows, we will be looking at the percentage or quantitative value of that performance.\n"
      ],
      "metadata": {
        "id": "5GGsLdzeb62e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset:\n",
        "\n",
        "Kaggle S&P 500 companiesâ€™ historical prices with fundamental data for the years 2012-2016\n",
        "https://www.kaggle.com/dgawlik/nyse?select=fundamentals.csv\n",
        "\n",
        "Yahoo Finance if more recent data are necessary"
      ],
      "metadata": {
        "id": "dZ38cE2acIE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master(\"local\") \\\n",
        "    .appName(\"review_and_category_analytics\") \\\n",
        "    .config(\"spark.executor.memory\", '8g') \\\n",
        "    .config('spark.executor.cores', '4') \\\n",
        "    .config('spark.cores.max', '4') \\\n",
        "    .config(\"spark.driver.memory\",'8g') \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "SLXFSU1BcK13",
        "outputId": "5c523137-bf99-4a71-982b-65a16b5a7081"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e70b6a27bc7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"local\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"review_and_category_analytics\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.executor.memory\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'8g'\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spark.executor.cores'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'4'\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spark.cores.max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'4'\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.driver.memory\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'8g'\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}